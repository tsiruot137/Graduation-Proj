{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook follows from the notebook `grib_test__FOR_0220_dataset_(grid-sampling_and_local-inspection).ipynb`. This notebook optimizes the computing of `ts_2mTemp` by parallelization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "msgs = pygrib.open(r\"C:\\SUSTech\\datasets_of_graduation_project\\0220.grib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid-sampling\n",
    "Given the lat-lon range (a rectangular region) of the dataset, the grid-sampling is to uniformly sample points from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_RANGE = (90, 66.5) # the entire map is from 90 degree to 66.5 degree, closed interval\n",
    "LON_RANGE = (-180, 179.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LAT_RESOL = 5 # the grid resolution of latitudes; two distinct lats are differred by 5 degrees\n",
    "LON_RESOL = 30\n",
    "LAT_VICINITY_R = 1 # Consider the average of the vicinity of each grid point, to reduce the noise. The radius of the vicinity is 1 degree here. This value should not exceed LAT_RESOL\n",
    "LON_VICINITY_R = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISTINCT_LATS = [90 - i * LAT_RESOL \n",
    "    for i in range(int((abs(LAT_RANGE[1] - LAT_RANGE[0]) // LAT_RESOL) + 1))] # round down when sampling points\n",
    "DISTINCT_LONS = [-180 + i * LON_RESOL \n",
    "    for i in range(int((abs(LON_RANGE[1] - LON_RANGE[0]) // LON_RESOL) + 1))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bidict({(90, -180): (0, 0), (90, -150): (0, 120), (90, -120): (0, 240), (90, -90): (0, 360), (90, -60): (0, 480), (90, -30): (0, 600), (90, 0): (0, 720), (90, 30): (0, 840), (90, 60): (0, 960), (90, 90): (0, 1080), (90, 120): (0, 1200), (90, 150): (0, 1320), (85, -180): (20, 0), (85, -150): (20, 120), (85, -120): (20, 240), (85, -90): (20, 360), (85, -60): (20, 480), (85, -30): (20, 600), (85, 0): (20, 720), (85, 30): (20, 840), (85, 60): (20, 960), (85, 90): (20, 1080), (85, 120): (20, 1200), (85, 150): (20, 1320), (80, -180): (40, 0), (80, -150): (40, 120), (80, -120): (40, 240), (80, -90): (40, 360), (80, -60): (40, 480), (80, -30): (40, 600), (80, 0): (40, 720), (80, 30): (40, 840), (80, 60): (40, 960), (80, 90): (40, 1080), (80, 120): (40, 1200), (80, 150): (40, 1320), (75, -180): (60, 0), (75, -150): (60, 120), (75, -120): (60, 240), (75, -90): (60, 360), (75, -60): (60, 480), (75, -30): (60, 600), (75, 0): (60, 720), (75, 30): (60, 840), (75, 60): (60, 960), (75, 90): (60, 1080), (75, 120): (60, 1200), (75, 150): (60, 1320), (70, -180): (80, 0), (70, -150): (80, 120), (70, -120): (80, 240), (70, -90): (80, 360), (70, -60): (80, 480), (70, -30): (80, 600), (70, 0): (80, 720), (70, 30): (80, 840), (70, 60): (80, 960), (70, 90): (80, 1080), (70, 120): (80, 1200), (70, 150): (80, 1320)})\n",
      "bidict({(0, 0): ((0, 5), (0, 5)), (0, 120): ((0, 5), (116, 125)), (0, 240): ((0, 5), (236, 245)), (0, 360): ((0, 5), (356, 365)), (0, 480): ((0, 5), (476, 485)), (0, 600): ((0, 5), (596, 605)), (0, 720): ((0, 5), (716, 725)), (0, 840): ((0, 5), (836, 845)), (0, 960): ((0, 5), (956, 965)), (0, 1080): ((0, 5), (1076, 1085)), (0, 1200): ((0, 5), (1196, 1205)), (0, 1320): ((0, 5), (1316, 1325)), (20, 0): ((16, 25), (0, 5)), (20, 120): ((16, 25), (116, 125)), (20, 240): ((16, 25), (236, 245)), (20, 360): ((16, 25), (356, 365)), (20, 480): ((16, 25), (476, 485)), (20, 600): ((16, 25), (596, 605)), (20, 720): ((16, 25), (716, 725)), (20, 840): ((16, 25), (836, 845)), (20, 960): ((16, 25), (956, 965)), (20, 1080): ((16, 25), (1076, 1085)), (20, 1200): ((16, 25), (1196, 1205)), (20, 1320): ((16, 25), (1316, 1325)), (40, 0): ((36, 45), (0, 5)), (40, 120): ((36, 45), (116, 125)), (40, 240): ((36, 45), (236, 245)), (40, 360): ((36, 45), (356, 365)), (40, 480): ((36, 45), (476, 485)), (40, 600): ((36, 45), (596, 605)), (40, 720): ((36, 45), (716, 725)), (40, 840): ((36, 45), (836, 845)), (40, 960): ((36, 45), (956, 965)), (40, 1080): ((36, 45), (1076, 1085)), (40, 1200): ((36, 45), (1196, 1205)), (40, 1320): ((36, 45), (1316, 1325)), (60, 0): ((56, 65), (0, 5)), (60, 120): ((56, 65), (116, 125)), (60, 240): ((56, 65), (236, 245)), (60, 360): ((56, 65), (356, 365)), (60, 480): ((56, 65), (476, 485)), (60, 600): ((56, 65), (596, 605)), (60, 720): ((56, 65), (716, 725)), (60, 840): ((56, 65), (836, 845)), (60, 960): ((56, 65), (956, 965)), (60, 1080): ((56, 65), (1076, 1085)), (60, 1200): ((56, 65), (1196, 1205)), (60, 1320): ((56, 65), (1316, 1325)), (80, 0): ((76, 85), (0, 5)), (80, 120): ((76, 85), (116, 125)), (80, 240): ((76, 85), (236, 245)), (80, 360): ((76, 85), (356, 365)), (80, 480): ((76, 85), (476, 485)), (80, 600): ((76, 85), (596, 605)), (80, 720): ((76, 85), (716, 725)), (80, 840): ((76, 85), (836, 845)), (80, 960): ((76, 85), (956, 965)), (80, 1080): ((76, 85), (1076, 1085)), (80, 1200): ((76, 85), (1196, 1205)), (80, 1320): ((76, 85), (1316, 1325))})\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from bidict import bidict\n",
    "msg = msgs[1]\n",
    "\n",
    "# (lat, lon) -> (lat_idx, lon_idx)\n",
    "latlon_to_latlonIdx = bidict()\n",
    "for lat in DISTINCT_LATS:\n",
    "    for lon in DISTINCT_LONS:\n",
    "        latlon_to_latlonIdx[(lat, lon)] = (np.where(msg[\"distinctLatitudes\"] == lat)[0][0], \n",
    "                                     np.where(msg[\"distinctLongitudes\"] == lon)[0][0])\n",
    "\n",
    "print(latlon_to_latlonIdx)\n",
    "\n",
    "# (lat_idx, lon_idx) -> ((lat1_idx, lat2_idx), (lon1_idx, lon2_idx)), \n",
    "# with lat1_idx <= lat2_idx, lon1_idx <= lon2_idx\n",
    "latlonIdx_to_vicinityIdx = bidict()\n",
    "for latlonIdx in latlon_to_latlonIdx.values():\n",
    "    lat_idx, lon_idx = latlonIdx\n",
    "    lat1_idx = int(max(0, \n",
    "                lat_idx - LAT_VICINITY_R // 0.25))\n",
    "    lat2_idx = int(min(len(msg[\"distinctLatitudes\"]), \n",
    "                lat_idx + LAT_VICINITY_R // 0.25 + 1))\n",
    "    lon1_idx = int(max(0, \n",
    "                lon_idx - LON_VICINITY_R // 0.25))\n",
    "    lon2_idx = int(min(len(msg[\"distinctLongitudes\"]), \n",
    "                lon_idx + LON_VICINITY_R // 0.25 + 1))\n",
    "    latlonIdx_to_vicinityIdx[latlonIdx] = ((lat1_idx, lat2_idx), (lon1_idx, lon2_idx))\n",
    "    \n",
    "print(latlonIdx_to_vicinityIdx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the `ts_2mTemp` for local inspection (parallelized)\n",
    "### Trial 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# if \"msg\" in locals(): del msg\n",
    "# ts_2mTemp = dict()\n",
    "# for (lat, lon) in latlon_to_latlonIdx.keys():\n",
    "#     ts_2mTemp[(lat, lon)] = np.array([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msgs.rewind()\n",
    "# msgs_len = sum(1 for _ in msgs)\n",
    "# print(msgs_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BATCH_SIZE = 100\n",
    "# batches_heads = list(range(1, msgs_len+1, BATCH_SIZE)) # the first batch starts with the 1st msg, the second batch starts with the 101st msg, and so on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compute_avg_for_latlon(latlon, batch_head):\n",
    "#     lat, lon = latlon\n",
    "#     lat1_idx, lat2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][0]\n",
    "#     lon1_idx, lon2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][1]\n",
    "    \n",
    "#     # compute the average of 2m-temps in the vicinity of (lat, lon) for this batch\n",
    "#     batch_ts_2mTemp = np.array([np.mean(msgs[t][\"values\"][lat1_idx:lat2_idx, lon1_idx:lon2_idx]) \n",
    "#                    for t in range(batch_head, min(batch_head+BATCH_SIZE, msgs_len+1))])\n",
    "    \n",
    "#     # 将计算结果直接存入ts_2mTemp字典\n",
    "#     ts_2mTemp[(lat, lon)] = np.concatenate((ts_2mTemp[(lat, lon)], batch_ts_2mTemp))\n",
    "\n",
    "# def compute_avg_for_msg(batch_head):\n",
    "#     # 使用线程池来并行计算每个batch的所有(lat, lon)的平均值，并直接更新ts_2mTemp\n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         # 对每个经纬度对进行并行处理\n",
    "#         futures = [executor.submit(compute_avg_for_latlon, latlon, batch_head) \n",
    "#                    for latlon in latlon_to_latlonIdx.keys()]\n",
    "        \n",
    "#         # 等待所有任务完成\n",
    "#         for future in futures:\n",
    "#             future.result()  # 这个步骤确保每个计算任务完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msgs.rewind()\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# for batch_head in tqdm(batches_heads, desc=\"Processing batches\", total=len(batches_heads), unit=\"batch\"):\n",
    "#     compute_avg_for_msg(batch_head)\n",
    "#     if batch_head == 101: print(\"The first batch has been processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import concurrent.futures\n",
    "\n",
    "# if \"msg\" in locals(): del msg\n",
    "\n",
    "# def process_latlon(lat, lon):\n",
    "#     lat1_idx, lat2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][0]\n",
    "#     lon1_idx, lon2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][1]\n",
    "#     return (lat, lon, np.array([np.mean(msg[\"values\"][lat1_idx:lat2_idx, lon1_idx:lon2_idx]) for msg in msgs]))\n",
    "\n",
    "# def parallel_processing():\n",
    "#     ts_2mTemp = dict()\n",
    "\n",
    "#     # 使用 ThreadPoolExecutor 来并行处理\n",
    "#     with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "#         futures = [\n",
    "#             executor.submit(process_latlon, lat, lon)\n",
    "#             for (lat, lon) in latlon_to_latlonIdx.keys()\n",
    "#         ]\n",
    "        \n",
    "#         for future in concurrent.futures.as_completed(futures):\n",
    "#             lat, lon, result = future.result()\n",
    "#             ts_2mTemp[(lat, lon)] = result\n",
    "\n",
    "#     return ts_2mTemp\n",
    "\n",
    "# ts_2mTemp = parallel_processing()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import concurrent.futures\n",
    "\n",
    "# if \"msg\" in locals(): del msg\n",
    "\n",
    "# def process_latlon(lat, lon):\n",
    "#     # 使用 get 方法来安全地访问字典\n",
    "#     latlon_idx = latlon_to_latlonIdx.get((lat, lon))\n",
    "#     if latlon_idx is None:\n",
    "#         return (lat, lon, np.array([]))  # 返回空数组，如果找不到对应的 latlon_idx\n",
    "    \n",
    "#     lat1_idx, lat2_idx = latlonIdx_to_vicinityIdx[latlon_idx][0]\n",
    "#     lon1_idx, lon2_idx = latlonIdx_to_vicinityIdx[latlon_idx][1]\n",
    "    \n",
    "#     # 计算均值，避免直接引用全局变量 msg，传递 msg 给子进程\n",
    "#     try:\n",
    "#         result = np.array([np.mean(msg[\"values\"][lat1_idx:lat2_idx, lon1_idx:lon2_idx]) for msg in msgs])\n",
    "#     except Exception as e:\n",
    "#         result = np.array([])  # 如果计算过程中有错误，返回空数组\n",
    "#         print(f\"Error processing {lat}, {lon}: {e}\")\n",
    "    \n",
    "#     return (lat, lon, result)\n",
    "\n",
    "# def parallel_processing():\n",
    "#     ts_2mTemp = dict()\n",
    "\n",
    "#     # 使用 ProcessPoolExecutor 来并行处理 CPU 密集型任务\n",
    "#     with concurrent.futures.ProcessPoolExecutor() as executor:\n",
    "#         futures = [\n",
    "#             executor.submit(process_latlon, lat, lon)\n",
    "#             for (lat, lon) in latlon_to_latlonIdx.keys()\n",
    "#         ]\n",
    "        \n",
    "#         for future in concurrent.futures.as_completed(futures):\n",
    "#             lat, lon, result = future.result()\n",
    "#             if result.size > 0:  # 只存储有效的结果\n",
    "#                 ts_2mTemp[(lat, lon)] = result\n",
    "\n",
    "#     return ts_2mTemp\n",
    "\n",
    "# # 调用并行处理函数\n",
    "# ts_2mTemp = parallel_processing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 4 (the only runable one, but still too slow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# if \"msg\" in locals(): del msg\n",
    "# ts_2mTemp = dict()\n",
    "# for (lat, lon) in latlon_to_latlonIdx.keys():\n",
    "#     ts_2mTemp[(lat, lon)] = np.array([])\n",
    "\n",
    "# def compute_avg_for_latlon(latlon, msg):\n",
    "#     lat, lon = latlon\n",
    "#     lat1_idx, lat2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][0]\n",
    "#     lon1_idx, lon2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][1]\n",
    "    \n",
    "#     # 计算该区域的平均值\n",
    "#     avg_value = np.mean(msg[\"values\"][lat1_idx:lat2_idx, lon1_idx:lon2_idx])\n",
    "    \n",
    "#     # 将计算结果直接存入ts_2mTemp字典\n",
    "#     ts_2mTemp[(lat, lon)] = np.append(ts_2mTemp[(lat, lon)], avg_value)\n",
    "\n",
    "# def compute_avg_for_msg(msg):\n",
    "#     # 使用线程池来并行计算每个msg的所有(lat, lon)的平均值，并直接更新ts_2mTemp\n",
    "#     with ThreadPoolExecutor(max_workers=60) as executor:\n",
    "#         # 对每个经纬度对进行并行处理\n",
    "#         futures = [executor.submit(compute_avg_for_latlon, latlon, msg) \n",
    "#                    for latlon in latlon_to_latlonIdx.keys()]\n",
    "        \n",
    "#         # 等待所有任务完成\n",
    "#         for future in futures:\n",
    "#             future.result()  # 这个步骤确保每个计算任务完成\n",
    "    \n",
    "\n",
    "# msgs.rewind()\n",
    "\n",
    "# from tqdm import tqdm\n",
    "# for msg in tqdm(msgs, desc=\"Processing msgs\", unit=\"msg\"):\n",
    "#     compute_avg_for_msg(msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from multiprocessing import Pool\n",
    "\n",
    "# # Initialize ts_2mTemp dictionary\n",
    "# ts_2mTemp = dict()\n",
    "\n",
    "# def compute_for_latlon(latlon):\n",
    "#     lat, lon = latlon\n",
    "#     msgs.rewind()\n",
    "#     lat1_idx, lat2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][0]\n",
    "#     lon1_idx, lon2_idx = latlonIdx_to_vicinityIdx[latlon_to_latlonIdx[(lat, lon)]][1]\n",
    "#     return (lat, lon), np.array([np.mean(msg[\"values\"][lat1_idx:lat2_idx, lon1_idx:lon2_idx]) for msg in msgs])\n",
    "\n",
    "# # List of latlon pairs\n",
    "# latlon_pairs = list(latlon_to_latlonIdx.keys())\n",
    "\n",
    "# # Use multiprocessing Pool to parallelize the computation\n",
    "# with Pool(processes=4) as pool:  # Adjust the number of processes as needed\n",
    "#     results = pool.map(compute_for_latlon, latlon_pairs)\n",
    "\n",
    "# # Update ts_2mTemp with the results\n",
    "# for (lat, lon), values in results:\n",
    "#     ts_2mTemp[(lat, lon)] = values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "main process end\n"
     ]
    }
   ],
   "source": [
    "# test for multiprocessing\n",
    "from multiprocessing import  Process\n",
    "\n",
    "def fun1(name):\n",
    "    print('test %s multi-processes' %name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_list = []\n",
    "    for i in range(5):  #开启5个子进程执行fun1函数\n",
    "        p = Process(target=fun1, args=('Python',)) #实例化进程对象\n",
    "        p.start()\n",
    "        process_list.append(p)\n",
    "\n",
    "    for i in process_list:\n",
    "        p.join()\n",
    "\n",
    "    print('main process end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "def fun1(name):\n",
    "    print('test %s multi-processes' % name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(5) as p:\n",
    "        p.map(fun1, ['Python'] * 5)\n",
    "\n",
    "    print('main process end')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msgs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3, 4, 5, 6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = [4, 5, 6]\n",
    "np.concatenate((a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# msgs.rewind()\n",
    "\n",
    "# import time\n",
    "\n",
    "# start = time.time()\n",
    "# t = 1\n",
    "# values = None\n",
    "# for msg in msgs:\n",
    "#     values = msg[\"values\"]\n",
    "#     t += 1\n",
    "#     if t == 100: break\n",
    "# end = time.time()\n",
    "# print(end-start, \"s\")\n",
    "\n",
    "# start = time.time()\n",
    "# t = 1\n",
    "# for t in range(1, 101):\n",
    "#     values = msgs[t][\"values\"]\n",
    "# end = time.time()\n",
    "# print(end-start, \"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
